{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Sveučilište u Zagrebu<br>\n",
    "Fakultet elektrotehnike i računarstva\n",
    "\n",
    "# Strojno učenje\n",
    "\n",
    "<a href=\"http://www.fer.unizg.hr/predmet/su\">http://www.fer.unizg.hr/predmet/su</a>\n",
    "\n",
    "Ak. god. 2015./2016.\n",
    "\n",
    "# Bilježnica 5: Regresija\n",
    "\n",
    "(c) 2015 Jan Šnajder\n",
    "\n",
    "<i>Verzija: 0.3 (2015-11-09)</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import scipy as sp\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sadržaj:\n",
    "\n",
    "* Uvod\n",
    "\n",
    "* Osnovni pojmovi\n",
    "\n",
    "* Model, funkcija gubitka i optimizacijski postupak\n",
    "\n",
    "* Postupak najmanjih kvadrata\n",
    "\n",
    "* Probabilistička interpretacija regresije\n",
    "\n",
    "* Poopćeni linearan model regresije\n",
    "\n",
    "* Odabir modela\n",
    "\n",
    "* Regularizirana regresija\n",
    "\n",
    "* Sažetak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Osnovni pojmovi\n",
    "\n",
    "* Označen skup podataka: $\\mathcal{D}=\\{(\\mathbf{x}^{(i)},y^{(i)})\\},\\quad \\mathbf{x}\\in\\mathbb{R}^n,\\quad y\\in\\mathbb{R}$\n",
    "\n",
    "\n",
    "* Hipoteza $h$ aproksimira nepoznatu  funkciju $f:\\mathbb{R}^n\\to\\mathbb{R}$\n",
    "\n",
    "\n",
    "* Idealno, $y^{(i)}=f(\\mathbf{x}^{(i)})$, ali zbog šuma: $$y^{(i)}=f(\\mathbf{x}^{(i)})+\\varepsilon$$\n",
    "\n",
    "\n",
    "* $\\mathbf{x}$ - **ulazna varijabla** (nezavisna, prediktorska)\n",
    "\n",
    "\n",
    "* $y$ - **izlazna varijabla** (zavisna, kriterijska)\n",
    "\n",
    "\n",
    "### Vrste regresije\n",
    "\n",
    "* Broj **ulaznih** (nezavisnih) varijabli:\n",
    "  * Univarijatna (jednostavna, jednostruka) regresija: $n=1$\n",
    "  * Multivarijatna (višestruka, multipla) regresija: $n>1$\n",
    "\n",
    "\n",
    "* Broj **izlaznih** (zavisnih) varijabli:\n",
    "  * Jednoizlazna regresija: $f(\\mathbf{x}) = y$\n",
    "  * Višeizlazna regresija: $f(\\mathbf{x})=\\mathbf{y}$\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model, funkcija gubitka i optimizacijski postupak\n",
    "\n",
    "\n",
    "### (1) Model\n",
    "\n",
    "* **Linearan model regresije**: $h$ je linearna funkcija <u>parametara</u>\n",
    "$\\mathbf{w} = (w_0,\\dots,w_n)$\n",
    "\n",
    "\n",
    "* Linearna regresija:\n",
    "    $$h(\\mathbf{x}|\\mathbf{w}) = w_0 + w_1 x_1 + w_2 x_2 + \\dots + w_n x_n$$\n",
    "\n",
    "\n",
    "* Polinomijalna regresija:\n",
    "    * Univarijatna polinomijalna: $$h(x|\\mathbf{w}) = w_0 + w_1 x + w_2 x^2 + \\dots + w_d x^d\\quad (n=1)$$\n",
    "    * Multivarijatna polinomijalna: $$h(\\mathbf{x}|\\mathbf{w}) = w_0 + w_1 x_1 + w_2 x_2 + w_3 x_1 x_2 + w_4 x_1^2 + w_5 x_2^2\\quad (n=2, d=2)$$\n",
    "      * Modelira međuovisnost značajki (*cross-terms* $x_1 x_2, \\dots$) \n",
    "\n",
    "\n",
    "* Općenite **bazne funkcije**:\n",
    "    $$h(\\mathbf{x}|\\mathbf{w}) = w_0 + w_1\\phi_1(\\mathbf{x}) + \\dots + w_m\\phi_m(\\mathbf{x})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Funkcija gubitka (funkcija pogreške)\n",
    "\n",
    "* Kvadratni gubitak (engl. *quadratic loss*)\n",
    "\n",
    "$$\n",
    "L(y^{(i)},h(\\mathbf{x}^{(i)})) = \\big(y^{(i)}-h(\\mathbf{x}^{(i)})\\big)^2\n",
    "$$\n",
    "\n",
    "* Funkcija pogreške (proporcionalna s empirijskim očekivanjem gubitka):\n",
    "$$\n",
    "E(h|\\mathcal{D})=\\frac{1}{2}\n",
    "\\sum_{i=1}^N\\big(y^{(i)}-h(\\mathbf{x}^{(i)})\\big)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Optimizacijski postupak\n",
    "\n",
    "* Postupak **najmanjih kvadrata** (engl. *least squares*)\n",
    "\n",
    "$$\n",
    "\\mathrm{argmin}_{\\mathbf{w}} E(\\mathbf{w}|\\mathcal{D})\n",
    "$$\n",
    "\n",
    "\n",
    "* Rješenje ovog optimizacijskog problema postoji u **zatvorenoj formi**\n",
    "\n",
    "\n",
    "# Postupak najmanjih kvadrata\n",
    "\n",
    "\n",
    "* Razmotrimo najprije linearnu regresiju:\n",
    "$$h(\\mathbf{x}|\\mathbf{w}) = w_0 + w_1 x_1 + w_2 x_2 + \\dots + w_n x_n = \\sum_{i=1}^n w_i x_i + w_0$$\n",
    "\n",
    "\n",
    "* Izračun je jednostavniji ako pređemo u matrični račun\n",
    "  * Svaki vektor primjera $\\mathbf{x}^{(i)}$ proširujemo *dummy* značajkom $x^{(i)}_0 = 1$, pa je model onda:\n",
    "\n",
    "$$h(\\mathbf{x}|\\mathbf{w}) = \\mathbf{w}^\\intercal \\mathbf{x}$$\n",
    "\n",
    "\n",
    "* Skup primjera:\n",
    "\n",
    "$$\n",
    "\\mathbf{X} = \n",
    "\\begin{pmatrix}\n",
    "1 & x^{(1)}_1 & x^{(1)}_2 \\dots & x^{(1)}_n\\\\\n",
    "1 & x^{(2)}_1 & x^{(2)}_2 \\dots & x^{(2)}_n\\\\\n",
    "\\vdots\\\\\n",
    "1 & x^{(N)}_1 & x^{(N)}_2 \\dots & x^{(N)}_n\\\\\n",
    "\\end{pmatrix}_{N\\times (n+1)}\n",
    "=\n",
    "\\begin{pmatrix}\n",
    "1 & (\\mathbf{x}^{(1)})^\\intercal \\\\\n",
    "1 & (\\mathbf{x}^{(2)})^\\intercal \\\\\n",
    "\\vdots\\\\\n",
    "1 & (\\mathbf{x}^{(N)})^\\intercal \\\\\n",
    "1 & \\end{